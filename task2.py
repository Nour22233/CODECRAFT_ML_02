# -*- coding: utf-8 -*-
"""Task2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XwFT7Hppdm7R8udiCDYQhmPWMpDkcIBZ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

df=pd.read_csv("Mall_Customers.csv")

df.head()

df.info()

df.isnull().sum()

df.duplicated().sum()

plt.figure(figsize=(8,4))
sns.histplot(df['Age'],kde=True,bins=20)
plt.title('age distribution')
plt.show()

plt.figure(figsize=(8,4))
sns.histplot(df['Spending Score (1-100)'],kde=True,bins=20)
plt.title('sepending distribution')
plt.show()

sns.pairplot(df)

plt.figure(figsize=(8,4))
sns.scatterplot(x=df['Age'],y=df['Spending Score (1-100)'],hue=df['Gender'])
plt.title('Age vs Spending Score')
plt.show()

plt.figure(figsize=(8,4))
sns.scatterplot(x=df['Annual Income (k$)'],y=df['Spending Score (1-100)'],hue=df['Gender'])
plt.title('Age vs Spending Score')
plt.show()

plt.figure(figsize=(12,4))
plt.subplot(1,3,1)
sns.boxplot(x='Gender', y='Age', data=df)
plt.subplot(1,3,2)
sns.boxplot(x='Gender', y='Annual Income (k$)', data=df)
plt.subplot(1,3,3)
sns.boxplot(x='Gender', y='Spending Score (1-100)', data=df)
plt.tight_layout()
plt.show()

from sklearn.preprocessing import StandardScaler

scale=StandardScaler()
cols=df[['Age', 'Annual Income (k$)', 'Spending Score (1-100)']]
cols_scale=scale.fit_transform(cols)

df['Gender']=df['Gender'].map({'Male':0,'Female':1})

df['Gender']

X = df.iloc[:, [3, 4]].values

X

from sklearn.cluster import KMeans
wcss=[]
for i in range(1,11):

    kmeans = KMeans(n_clusters = i, init = 'k-means++')
    kmeans.fit(X)
    print('Cost_Function=',kmeans.inertia_,'with', i, 'Clusters')
    wcss.append(kmeans.inertia_)

plt.plot(range(1,11),wcss)
plt.title("The Elbow methods")
plt.xlabel("NUmber of clustring")
plt.ylabel("Wcss")
plt.show()

kmeans=KMeans(n_clusters=3,init="k-means++",random_state=42)
y_kmeans=kmeans.fit_predict(X)

plt.scatter(X[y_kmeans ==0,0],X[y_kmeans==0,1],s=100,c='red',label='cluster 1')
plt.scatter(X[y_kmeans ==1,0],X[y_kmeans==1,1],s=100,c='blue',label='cluster 2')
plt.scatter(X[y_kmeans ==2,0],X[y_kmeans==2,1],s=100,c='green',label='cluster 3')
plt.scatter(X[y_kmeans ==3,0],X[y_kmeans==3,1],s=100,c='cyan',label='cluster 4')
plt.scatter(X[y_kmeans ==4,0],X[y_kmeans==4,1],s=100,c='magenta',label='cluster 5')
plt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],s=300,c='yellow',label="Centroids")
plt.title("clustirng of coustomers")
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.legend()
plt.show()

df['cluster']=kmeans.fit_predict(cols_scale)
cluster_gender=df.groupby('cluster')['Gender'].value_counts().reset_index()
print(cluster_gender)

from sklearn.neighbors import NearestNeighbors

X = df.iloc[:, [3, 4]].values

def plot_K_distance(X,K):
    neigh=NearestNeighbors(n_neighbors=K)
    neigh.fit(X)
    distance,_=neigh.kneighbors(X)
    distance=np.sort(distance[:,K-1])

    plt.figure(figsize=(10,6))
    plt.plot(distance)
    plt.xlabel("points")
    plt.ylabel(f"{K}-the nearst neighbor distance")
    plt.title('K-distance Graph')
    plt.show()
plot_K_distance(X,K=5)

from sklearn.cluster import DBSCAN
dbscan=DBSCAN(eps=10,min_samples=3).fit(X)
core_sample=np.zeros_like(dbscan.labels_,dtype=bool)
core_sample[dbscan.core_sample_indices_]
labels=dbscan.labels_
clusters=dbscan.fit_predict(X)

labels

clusters

from sklearn import metrics

n_cluter=len(set(labels))-(1 if -1 in labels else 0)
n_noise=list(labels).count(-1)
print('Estimated number of clusters: %d' % n_cluter)
print('Estimated number of noise points: %d' % n_noise)

unique_labels = set(labels)
colors = [plt.cm.Spectral(each)
          for each in np.linspace(0, 1, len(unique_labels))]
for k, col in zip(unique_labels, colors):
    if k == -1:

        col = [0, 0, 0, 1]

    class_member_mask = (labels == k)

    xy = X[class_member_mask & core_sample]
    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),
             markeredgecolor='k', markersize=14)

    xy = X[class_member_mask & ~core_sample]
    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=tuple(col),
             markeredgecolor='k', markersize=6)

plt.title('Estimated number of clusters: %d' % n_cluter)
plt.show()

from scipy.cluster.hierarchy import linkage,dendrogram,cut_tree

merge=linkage(X,method='single',metric="euclidean")
dendrogram(merge)
plt.show()

merge=linkage(X,method='complete',metric="euclidean")
dendrogram(merge)
plt.show()

merge=linkage(X,method='average',metric="euclidean")
dendrogram(merge)
plt.show()

cluster_lablel=cut_tree(merge,n_clusters=3).reshape(-1,)
cluster_lablel

merge=linkage(X,method='ward',metric="euclidean")
dendrogram(merge)
plt.show()

df['Cluster_Labels']=cluster_lablel
df.head()

from sklearn.metrics import silhouette_score

score=silhouette_score(X,cluster_lablel)
print("sihouette Score",score)

from sklearn.metrics import calinski_harabasz_score

ch=calinski_harabasz_score(X,cluster_lablel)
print("Calinski-Harabasz Index:", ch)

from sklearn.metrics import davies_bouldin_score
db=davies_bouldin_score(X,cluster_lablel)
print("davies_bouldin_score: ",db)

import matplotlib.pyplot as plt
plt.scatter(X[:, 0], X[:, 1], c=cluster_lablel, cmap='viridis')
plt.title("Clustering Visualization")
plt.show()

